{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento de GNN GraphSAGE\n",
    "\n",
    "Este notebook demonstra como carregar um grafo de dependências, construir um modelo **GraphSAGE** usando PyTorch Geometric e registrar métricas e modelos no MLflow. O grafo é lido a partir do JSON gerado pelo script `generate_graph.py`. Caso você não tenha features para os nós, serão geradas features aleatórias combinadas com codificação one-hot das categorias.\n",
    "\n",
    "> **Nota:** para executar este notebook, é necessário ter o PyTorch, PyTorch Geometric e MLflow instalados no ambiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv\n",
    "import mlflow\n",
    "\n",
    "# Define função para carregar grafo\n",
    "def load_graph(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# Define função para construir dataset a partir do grafo\n",
    "def build_dataset(graph):\n",
    "    nodes = graph['nodes']\n",
    "    edges = graph['edges']\n",
    "    categories = sorted(set(n['category'] for n in nodes))\n",
    "    cat_to_idx = {cat: i for i, cat in enumerate(categories)}\n",
    "    num_nodes = len(nodes)\n",
    "    num_cats = len(categories)\n",
    "    rand_dim = 16\n",
    "    x_rand = np.random.randn(num_nodes, rand_dim).astype(np.float32)\n",
    "    x_onehot = np.zeros((num_nodes, num_cats), dtype=np.float32)\n",
    "    for i, n in enumerate(nodes):\n",
    "        x_onehot[i, cat_to_idx[n['category']]] = 1.0\n",
    "    x = np.concatenate([x_rand, x_onehot], axis=1)\n",
    "    y = np.array([cat_to_idx[n['category']] for n in nodes], dtype=np.int64)\n",
    "    edge_list = []\n",
    "    for e in edges:\n",
    "        s = e['source'] - 1\n",
    "        t = e['target'] - 1\n",
    "        edge_list.append((s, t))\n",
    "        edge_list.append((t, s))\n",
    "    edge_index = torch.tensor(edge_list, dtype=torch.long).t().contiguous()\n",
    "    data = Data(x=torch.tensor(x, dtype=torch.float32), edge_index=edge_index, y=torch.tensor(y))\n",
    "    return data, categories\n",
    "\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "def train(data, num_classes, run_name='gnn_notebook', mlflow_uri='http://127.0.0.1:5000'):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    data = data.to(device)\n",
    "    model = GraphSAGE(data.x.size(1), 32, num_classes).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    num_nodes = data.num_nodes\n",
    "    idx = np.arange(num_nodes)\n",
    "    np.random.shuffle(idx)\n",
    "    split = int(0.8 * num_nodes)\n",
    "    train_idx = torch.tensor(idx[:split], dtype=torch.long, device=device)\n",
    "    test_idx = torch.tensor(idx[split:], dtype=torch.long, device=device)\n",
    "    mlflow.set_tracking_uri(mlflow_uri)\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        mlflow.log_param('num_nodes', num_nodes)\n",
    "        mlflow.log_param('num_classes', num_classes)\n",
    "        for epoch in range(1, 21):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data.x, data.edge_index)\n",
    "            loss = F.cross_entropy(out[train_idx], data.y[train_idx])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                logits = model(data.x, data.edge_index)\n",
    "                pred = logits.argmax(dim=1)\n",
    "                train_acc = (pred[train_idx] == data.y[train_idx]).float().mean().item()\n",
    "                test_acc = (pred[test_idx] == data.y[test_idx]).float().mean().item()\n",
    "            mlflow.log_metric('train_loss', loss.item(), step=epoch)\n",
    "            mlflow.log_metric('train_accuracy', train_acc, step=epoch)\n",
    "            mlflow.log_metric('test_accuracy', test_acc, step=epoch)\n",
    "            print(f'Epoch {epoch:02d} loss={loss.item():.4f} train_acc={train_acc:.3f} test_acc={test_acc:.3f}')\n",
    "        # salva modelo\n",
    "        mlflow.pytorch.log_model(model, artifact_path='model')\n",
    "        mlflow.log_param('framework', 'pytorch_geometric')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o grafo de exemplo e constrói o dataset\n",
    "graph_path = '../data/sample_graph.json'  # ajuste este caminho conforme necessário\n",
    "graph = load_graph(graph_path)\n",
    "data, categories = build_dataset(graph)\n",
    "print(f'Número de nós: {data.num_nodes}, número de classes: {len(categories)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treina o modelo e registra no MLflow\n",
    "trained_model = train(data, num_classes=len(categories), run_name='gnn_notebook_experiment')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}